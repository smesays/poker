{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1200 (0%)]\tLoss: 1.793135\n",
      "Train Epoch: 0 [500/1200 (42%)]\tLoss: 1.786929\n",
      "Train Epoch: 0 [1000/1200 (83%)]\tLoss: 1.796950\n",
      "Train Epoch: 1 [0/1200 (0%)]\tLoss: 1.790215\n",
      "Train Epoch: 1 [500/1200 (42%)]\tLoss: 1.778614\n",
      "Train Epoch: 1 [1000/1200 (83%)]\tLoss: 1.805952\n",
      "Train Epoch: 2 [0/1200 (0%)]\tLoss: 1.779331\n",
      "Train Epoch: 2 [500/1200 (42%)]\tLoss: 1.772827\n",
      "Train Epoch: 2 [1000/1200 (83%)]\tLoss: 1.804612\n",
      "Train Epoch: 3 [0/1200 (0%)]\tLoss: 1.799015\n",
      "Train Epoch: 3 [500/1200 (42%)]\tLoss: 1.786619\n",
      "Train Epoch: 3 [1000/1200 (83%)]\tLoss: 1.789544\n",
      "Train Epoch: 4 [0/1200 (0%)]\tLoss: 1.776237\n",
      "Train Epoch: 4 [500/1200 (42%)]\tLoss: 1.798314\n",
      "Train Epoch: 4 [1000/1200 (83%)]\tLoss: 1.784218\n",
      "Train Epoch: 5 [0/1200 (0%)]\tLoss: 1.783657\n",
      "Train Epoch: 5 [500/1200 (42%)]\tLoss: 1.787669\n",
      "Train Epoch: 5 [1000/1200 (83%)]\tLoss: 1.792049\n",
      "Train Epoch: 6 [0/1200 (0%)]\tLoss: 1.800703\n",
      "Train Epoch: 6 [500/1200 (42%)]\tLoss: 1.800264\n",
      "Train Epoch: 6 [1000/1200 (83%)]\tLoss: 1.778535\n",
      "Train Epoch: 7 [0/1200 (0%)]\tLoss: 1.786758\n",
      "Train Epoch: 7 [500/1200 (42%)]\tLoss: 1.795728\n",
      "Train Epoch: 7 [1000/1200 (83%)]\tLoss: 1.799432\n",
      "Train Epoch: 8 [0/1200 (0%)]\tLoss: 1.812505\n",
      "Train Epoch: 8 [500/1200 (42%)]\tLoss: 1.785281\n",
      "Train Epoch: 8 [1000/1200 (83%)]\tLoss: 1.789532\n",
      "Train Epoch: 9 [0/1200 (0%)]\tLoss: 1.790182\n",
      "Train Epoch: 9 [500/1200 (42%)]\tLoss: 1.793357\n",
      "Train Epoch: 9 [1000/1200 (83%)]\tLoss: 1.798150\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Global Parameters:\n",
    "BATCH_SIZE = 10\n",
    "IS_CUDA    = False\n",
    "LR         = 0.03\n",
    "MOMENTUM   = 1e-6\n",
    "EPOCHS      = 10\n",
    "LOG_IN     = 50\n",
    "\n",
    "# Load Dataset\n",
    "def load_dataset(txt_filepath):\n",
    "    \n",
    "    # PLace to load the informaton we have\n",
    "    #features = np.loadtxt(txt_filepath).T\n",
    "    #data = []\n",
    "    #target = []\n",
    "    #for i in range(1,7):\n",
    "    #    for _ in range(200):\n",
    "    #        data.append(np.random.randint(5*i, size=20))\n",
    "    #         target.append(i)\n",
    "    data = np.random.randint(5, size=(1200, 20))\n",
    "    target = np.random.randint(6, size=1200)\n",
    "    return np.sort(data[:]), np.sort(target)\n",
    "\n",
    "# Global objects:\n",
    "class PokerDataset(Dataset):\n",
    "\n",
    "    def __init__(self, txt_filepath):\n",
    "        self.data, self.target = load_dataset(txt_filepath)\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index,:], self.target[index] \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "# Network Architecture:\n",
    "class BlueNet_all(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BlueNet_all, self).__init__()\n",
    "        self.layer1 = nn.Linear(20, 40)\n",
    "        self.layer2 = nn.Linear(40, 120)\n",
    "        self.layer3 = nn.Linear(120, 60)\n",
    "        self.layer4 = nn.Linear(60, 30)\n",
    "        self.layer5 = nn.Linear(30, 6)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        fc1 = F.relu(self.layer2(self.relu((self.layer1(x)))))\n",
    "        out_x = self.layer5(self.relu(self.layer4(self.relu((self.layer3(fc1))))))\n",
    "        return out_x\n",
    "\n",
    "train_set = PokerDataset(0)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "model = BlueNet_all()\n",
    "if IS_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "# Use MSE as Reconstrcution Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # reshape to vector\n",
    "        #data = data.view(data.size(0), -1)\n",
    "        # move to cuda if available\n",
    "        if IS_CUDA:\n",
    "            data = data.cuda()\n",
    "        # convert to Variable\n",
    "        data = Variable(data.type(torch.FloatTensor))\n",
    "        target = Variable(target.type(torch.LongTensor))\n",
    "        # forward: evaluate with model\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        # backward: compute gradient and update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_IN == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "best_acc = 0\n",
    "# run training\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\n",
    "    #test_loss = test(show_plot=epoch%10 == 1)\n",
    "    #if test_loss < best_loss:\n",
    "    #    best_loss = test_loss\n",
    "    #    if args.is_noisy:\n",
    "    #        torch.save(model.state_dict(), 'best_fc_denoising_autoencoder.pth')\n",
    "    #    else:\n",
    "    #        torch.save(model.state_dict(), 'best_fc_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f852768f863d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python2.7/random.pyc\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(self, x, random)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mrandom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0m_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;31m# pick an element in x[:i+1] with which to exchange x[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(random.choice(range(100000)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
